---
title: "Testing"
subtitle: How else do we know it works?
format:
    revealjs:
        slide-number: true
        preview-links: auto
        theme: [../../custom_slides.scss]
        css: ../../slides.css
        view-distance: 100
        mobile-view-distance: 100
        navigation-mode: vertical
        controls-layout: bottom-right
        controls-tutorial: true

footer: \
    <a href="https://opensourcecourse.dev/modules/testing/overview.html">overview</a> /\
    <a href="https://github.com/opensourcecourse/opencourse/blob/main/modules/testing/slides.qmd">source</a> /\
    <a href="https://opensourcecourse.dev/modules/testing/exercises.html">exercises</a>
---


# Motivation {auto-animate="true" visibility="uncounted"}

<br>

```{python}
#| echo: true
#| eval: false

def add(thing1, thing2):
    """A function to add things."""
    return thing1 + thing2
```
<br>

:::{.fragment}
Does it work?
:::

:::{.fragment}
Is it correct?
:::

:::{.fragment}
How can we prove it?
:::


# Motivation {auto-animate="true" visibility="uncounted"}

<br>

```{python}
#| echo: true
#| eval: false

def add(thing1, thing2):
    """A function to add things."""
    return thing1 + thing2

out = add(1, 1)
```



# Motivation {auto-animate="true" visibility="uncounted"}

<br>

```{python}
#| echo: true
#| eval: false

def add(thing1, thing2):
    """A function to add things."""
    return thing1 + thing2

out = add(1.0, 1)
```



# Motivation {auto-animate="true" visibility="uncounted"}

<br>

```{python}
#| echo: true
#| eval: false

def add(thing1, thing2):
    """A function to add things."""
    return thing1 + thing2

out = add(1.0, '1')
```



# Motivation {auto-animate="true" visibility="uncounted"}

<br>

```{python}
#| echo: true
#| eval: false

def add(thing1, thing2):
    """A function to add things."""
    return thing1 + thing2

out = add([1.0, 2.0], 1.0)
```


<!-- Code planes: analogy for different testing types -->


# Code Planes: Desired Behavior

```{python}
#| echo: false
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import axes3d

plt.rcParams.update({
    "figure.facecolor":  (0.0, 0.0, 0.0, 0.0),  # red   with alpha = 30%
    "axes.facecolor":    (0.0, 1.0, 0.0, 0.0),  # green with alpha = 50%
    "savefig.facecolor": (0.0, 0.0, 1.0, 0.0),  # blue  with alpha = 20%
})

x, y, z = axes3d.get_test_data(0.03)


def plot_wireframe(X, Y, Z, ax=None, color='blue', alpha=0.5, label=None):
    if ax is None:
        fig = plt.figure(figsize=(15,15))
        ax = fig.add_subplot(projection='3d')
        ax.set_axis_off()
        fig = plt.figure()

    if np.array(Z).shape != X.shape:
        Z = np.ones_like(X) * Z

    # Plot a basic wireframe.
    ax.plot_wireframe(
        X, Y, Z, rstride=10, cstride=10, color=color, alpha=alpha, label=label,
    )

    return ax
```


:::{.absolute top=-200 left=20}

```{python}
#| echo: false

ax = plot_wireframe(x, y, np.median(z), color='blue', label='desired behavior')
plt.show()
```

:::



# Code Planes: Actual Behavior

:::{.absolute top=-200 left=20}

```{python}
#| echo: false

ax = plot_wireframe(x, y, z, color='red', label='actual behavior')
plt.show()
```

:::



# Testing Taxonomy

::: {.columns}

::: {.column width="50%"}

**Testing** [Domains]{.red-bold}

(What the planes mean)

:::{.incremental}

- Compilation
- Unit
- Integration
- End to End

:::

:::

::: {.column width="50%"}

**Testing** [Approaches]{.blue-bold}

(How we measure residuals)

:::{.incremental}

- Example
- Property
- Mutation
- Mathematical

:::

:::

:::

:::{.fragment}

- [Level of Automation]{.green-bold} is also important

:::



# Testing [Domains]{.red-bold}


:::{.r-stack}
<br>
![](images/test_pyramid.png){width="550"}

:::

# Testing [Domains]{.red-bold}: Unit
<br>

```python
def test_raises_value_error_if_sparse():
    error_msg = "dense data is required."
    # X must not be sparse if positive == True
    X = sparse.eye(10)
    y = np.ones(10)

    reg = LinearRegression(positive=True)

    with pytest.raises(TypeError, match=error_msg):
        reg.fit(X, y)

```

::: footer
Example modified from [here](https://github.com/scikit-learn/scikit-learn/blob/e2dd39194d613eb0f011450cc41831cc429c67c9/sklearn/linear_model/tests/test_base.py#L95)
:::



# Testing [Domains]{.red-bold}: Integration

```python
def test_pipeline_methods_anova():
    X, Y = iris.data, iris.target
    # Test with Anova + LogisticRegression
    clf = LogisticRegression()
    filter1 = SelectKBest(f_classif, k=2)
    anova = ("anova", filter1)
    logistic = ("logistic", clf)
    pipe = Pipeline([anova, logistic])
    pipe.fit(X, y)
    pipe.predict(X)
    pipe.predict_proba(X)
    pipe.predict_log_proba(X)
    pipe.score(X, y)
```

::: footer
Example modified from [here](https://github.com/scikit-learn/scikit-learn/blob/754bd5245aa46b89a1d686a3326c2b853012ff3e/sklearn/tests/test_pipeline.py#L264-L276)
:::



# Testing [Domains]{.red-bold}: End to End (E2E)

```python
def test_user_story_1():
    # read data from disk
    spool = dc.load('example_files')
    # chunk data, filter
    out = []
    for patch in spool.chunk(time=10):
        pa = patch.pass_filter(time=(None, 10))
        out.append(pa)
    # create new spool
    proc_spool = dc.spool(out)
    # plot first patch
    proc_spool[0].viz.waterfall(show=True)
    # save to disk
    proc_spool.io.write('processed', 'DASDAE')
```



# Testing [Approaches]{.blue-bold}: Example
<br>


:::{.incremental}

- Pick out example inputs
- Ensure expected and actual behavior match
- Include inputs related to bugs
- How do we know when we have picked enough examples?

:::


# Testing [Approaches]{.blue-bold}: Example
<br>

```python
def add(thing1, thing2):
    return thing1 + thing2

def test_add_some_floats():
    """Add floats together"""
    assert add(1., 3.) == 4.
    assert add(10., 12.) == 22.
    assert add(-5., 5.) == 0.
```



# Testing [Approaches]{.blue-bold}: Example

:::{.absolute top=-200 left=20}

```{python}
#| echo: false

new_z = np.copy(z)
shape = z.shape
rand = np.random.RandomState(33)


# create x/y pair
x_vals, y_vals = [], []
for _ in range(50):
    x_vals.append(rand.randint(0, shape[0]))
    y_vals.append(rand.randint(0, shape[1]))

# set new_z values to expected value for pair.
for x_ind, y_ind in zip(x_vals, y_vals):
    new_z[x_ind-3:x_ind + 3, y_ind - 3:y_ind + 3] = np.median(z)
    


ax = plot_wireframe(x, y, new_z, color='red', label='actual behavior')

# set new_z values to expected value for pair.
for x_ind, y_ind in zip(x_vals, y_vals):
    xval = x[x_ind, y_ind]
    yval = y[x_ind, y_ind]
    ax.scatter(
        xval, yval, np.median(z), color='blue',
    )
plt.show()
```

:::



# Testing [Approaches]{.blue-bold}: Property
<br>

:::{.incremental}

- Generate many examples (distribution)
- Keep track of failures
- Emphasis on edge cases (eg 0, -1 NaN, inf)
- Tests can take much longer
- Non-deterministic

:::


# Testing [Approaches]{.blue-bold}: Property

<br>

```python
from hypothesis import given
import hypothesis.strategies as st

def add(thing1, thing2):
    return thing1 + thing2

# The framework injects f1/f2 into test many times
@given(f1=st.floats(), f2=st.floats())
def test_add_many_floats_floats(f1, f2):
    """Add floats together"""
    assert add(f1, f2) == f1 + f2
```



# Testing [Approaches]{.blue-bold}: Property

:::{.absolute top=-200 left=20}

```{python}
#| echo: false

new_z = np.copy(z)

ind = 100

new_z[:, ind - 6: ind + 6] = np.median(z)

ax = plot_wireframe(x, y, new_z, color='red', label='actual behavior')

# set new_z values to expected value for pair.
for xval, yval in zip(x[:, ind], y[:, ind]):
    ax.scatter(
        xval, yval, np.median(z), color='blue',
    )
plt.show()
```

:::


# Testing [Approaches]{.blue-bold}: Mutation

:::{.r-stack}
![](images/sentinel.jpg){width="400"}
:::

:::{.footer}
image source [here](https://preview.redd.it/ikue937n15u71.jpg?auto=webp&s=a94c95751fd5f3b718950e3cf9d4cc3384c2b4f4)
:::


# Testing [Approaches]{.blue-bold}: Mutation
<br>

:::{.incremental}

- Approach to test the tests
- Make syntactically valid changes to the code
- Run the test suite
- Expects a test failure -> "killed the mutant""

:::



# Testing [Approaches]{.blue-bold}: Mutation {auto-animate=true}
<br>
Original function and tests

```python
def add(thing1, thing2):
    return thing1 + thing2

def test_add_floats():
    """Test add floats together"""
    assert add(1., 2.) == 3.
    assert add(2., 2.) == 4.
```



# Testing [Approaches]{.blue-bold}: Mutation {auto-animate=true}

<br>

Mutated function (tests unchanged)

```{.python code-line-numbers="|2"}
def add(thing1, thing2):
    return thing1 - thing2

def test_add_floats():
    """Test add floats together"""
    assert add(1., 2.) == 3.
    assert add(2., 2.) == 4.
```




# Testing [Approaches]{.blue-bold}: Mutation

:::{.absolute top=-200 left=20}

```{python}
#| echo: false

rand = np.random.RandomState(33)

new_z = z + rand.randint(0, 10, size=new_z.shape) * np.std(z)/40

ax = plot_wireframe(x, y, new_z, color='red', label='actual behavior')
plt.show()
```

:::


# Testing [Approaches]{.blue-bold}: Mathematical

<br>

:::{.incremental}
- Pure functional languages can be proven correct via formal proofs
- How can we prove the proof is correct? 
- Possible, but difficult in practice
:::



# When/How to Test? 


:::{.absolute top=150 left=120}

The law of diminishing returns applies!

```{python}
#| echo: false
import matplotlib.pyplot as plt
import numpy as np

with plt.xkcd():
    x = np.arange(100)
    
    y = np.log10(x)
    
    plt.plot(x, y)
    
    plt.xlabel("Testing Efforts")
    plt.ylabel("Quality Improvements")
    plt.xticks([])
    plt.yticks([])
plt.show()
```

:::


# When/How to Test? 

Selecting the right level of testing

<br>

:::{.incremental}
- How long will the software be in use? 
- How many people will interact with the software?
- What are the consequences of failure?
- How many lines of code/files could this grow to?
:::


# When/How to Test? 

<br>

:::{.incremental}
- Running a few E2E tests (does it generate figures, does it look right?) 
- Writing targeted unit tests (most important/difficult parts)
- Simple tests can be in the same files as code
- For libraries/applications use a testing framework!
:::


# Single File Tests

<br>

```python
def add(thing1, thing2):
    return thing1 - thing2

def test_add_many_floats_floats():
    """Test add floats together"""
    assert add(1., 2.) == 3.
    assert add(2., 2.) == 4.

if __name__ == "__main__":
    test_add_many_floats_floats()
```



# [Pytest](https://docs.pytest.org/en/7.2.x/)

<br>

:::{.incremental}

- De-facto python testing framework (apart from unittest)
- Highly extensible (100+ plugins)
- Separates setup, testing, teardown
- Configurable with commandline arguments

:::

:::{.fragement}

:::{.r-stack}
![](https://docs.pytest.org/en/7.1.x/_static/pytest_logo_curves.svg){width="180"}
:::

:::


# Pytest

How to use pytest?

:::{.incremental}
 - Call `pytest` from the command line, it will then:
 - Parse command line arguments 
 - [Discover tests](https://docs.pytest.org/en/7.1.x/explanation/goodpractices.html#conventions-for-python-test-discovery) (files: test\*)
 - Collect tests and fixtures (classes Test\*, functions/methods test\*)
 - Resolve fixture/test dependencies
 - Run selected tests
:::


# Pytest {auto-animate=true}

pytest to test our add function:

```{.python filename="test_add.py"}
# assumes add function is in myadd.py
from myadd import add 

def test_add_floats():
    """Test add floats together"""
    assert add(1., 2.) == 3.
    assert add(2., 2.) == 4.
```


# Pytest {auto-animate=true}

Organizing tests

```{.python filename="test_add.py"}
from mymodule import add

def test_add_floats():
    ...

def test_add_strings():
    ...
   
def test_add_lists():
    ...
```


# Pytest {auto-animate=true}

Organizing tests

```{.python filename="test_add.py"}
from mymodule import add

class TestAdd:
    def test_add_floats(self):
        ...
    
    def test_add_strings(self):
        ...
       
    def test_add_lists(self):
        ...
```


# Pytest

Example: Write extra tests for numpy's linalg norm


```{.python filename="test_norm.py" code-line-numbers="1||3-5|7-11"}
import numpy as np

def test_l2_norm_positive():
    random = np.rand.random(100)
    assert np.linalg.norm(random, ord=2) > 0

def test_nan_returns_nan():
    random = np.rand.random(100)
    random[10] = np.NaN
    out = np.linalg.norm(random)
    assert np.isnan(out)
```



# Pytest

Run tests from the command line using `pytest`.

```bash
pytest
```

:::{.fragment}

![](images/test_run.png)

:::

:::{.fragment}

```bash
pytest test_norm.py
```

:::

<br>


:::{.fragment}

```bash
pytest test_norm.py::test_nan_returns_nan
```

:::


# Knowledge Check

<br>

What domain and approach does test_norm use?

:::{.fragment}
[Domain]{.red-bold}: Unit

[Approach]{.blue-bold}: Example

:::



# Pytest: Testing Errors

<br>

```{.python filename="test_add.py" code-line-numbers="1||6,7|8"}
import pytest

from mymodule import add

def test_add_string_num_raises():
    msg = "unsupported operand type"
    with pytest.raises(TyperError, match=msg):
        add(1, '1')
```


# Pytest: Parametrization

```{.python filename="test_add.py" code-line-numbers="1||4-8|10|11-12"}
import pytest
from mymodule import add

io_tuple = (
    (1, 2, 3),
    (4, 5, 6),
    ("a", "b", "ab"),
)

@pytest.mark.parametrize("a,b,expected", io_tuple)
def test_add_string_num_raises(a, b, expected):
    assert add(a, b) == expected
```

# Anatomy of a Software Test

<br>

:::{.incremental}
- Arrange - setup test conditions
- Act - perform behavior under test
- Assert - measure difference between expected and observed
- Cleanup - put program state back in order
:::


:::{.footer}

https://docs.pytest.org/en/6.2.x/fixture.html#what-fixtures-are

:::


# Anatomy of a Software Test

<br>

```{.python code-line-numbers="1||5-6|7|8|9"}
from myadd import add 

def test_add_many_floats_floats():
    """Test add floats together"""
    value_1 = 1.
    value_2 = 2.
    out = add(value_1, value_2)
    assert out == 3
    del value_1, value_2
```


# Pytest: Fixtures

<br>

:::{.incremental}
- Used to manage arrange, cleanup (and sometimes act)
- Can "inject" objects under test
- Scope controls when fixtures run 
- Tests "request" fixtures by using their name as parameters
- Many useful built-in fixtures (tmp_path, monkeypatch, capsys) 
:::



# Pytest: Fixtures


```{.python filename="test_norm1.py" code-line-numbers="1|4-9|6-7|8,11|12|13|9|"}
import numpy as np
import pytest

@pytest.fixture()
def array_with_nans():
    random = np.rand.random(100)
    random[10] = np.NaN
    yield random
    del random

def test_nan_returns_nan(array_with_nans):
    out = np.linalg.norm(array_with_nans)
    assert np.isnan(out)
```



# Pytest: Fixtures Scope {auto-animate=true}


Scopes control how often fixtures are run: 
 "function", "class", "module", "package", "session" 

```{.python filename="test_norm1.py"}
import numpy as np
import pytest

@pytest.fixture(scope='class')
def array_with_nans():
    random = np.rand.random(100)
    random[10] = np.NaN
    yield random
    del random
```


# Knowledge Check

What's wrong here?
```{.python}
import numpy as np
import pytest

@pytest.fixture()
def data():
    return [1, 2, 3]
    
def test_data_1():
    assert isinstance(data, list)
```
:::{.fragment}
test_data_1 needs the data argument!
:::


# Knowledge Check

What's wrong here? How can we fix it?
```{.python code-line-numbers="1||4|9"}
import numpy as np
import pytest

@pytest.fixture(scope='session')
def data():
    return [1, 2, 3]
    
def test_data_1(data):
    data[0] = 10

def test_data_2(data):
    assert sum(data) == 6
```


# Pytest Marks

<br>

:::{.incremental}
- Marks allow organizing tests/fixtures/modules
  - Custom marks defined in pytest.ini or pyproject.toml
- Running tests can be controlled by marks
- Marks can also skip/xfail
- Marks can control parametrization
:::



# Pytest Marks

```{.python code-line-numbers="1||3-4|7-8|11-12|15-16"}
import pytest
    
@pytest.mark.slow
def test_make_new_friends():
    ...

@pytest.mark.skip(reason="Not safe!")
def test_gaze_into_the_abyss():
    ...
    
@pytest.mark.skipif(on_windows, reason="windows sucks")
def test_do_useful_things():
    ...
    
@pytest.mark.xfail
def test_impress_my_father():
    ...
```



# Pytest Marks

<br>

```python
import pytest
 
pytestmark = pytest.mark.slow

@pytest.mark.webtest
class TestDownloadData:
    ...
```


# Pytest Marks

<br>

Run slow tests

```bash
pytest -m slow
```

:::{.fragment}

<br>

Run slow but not webtests

```bash
pytest -m "slow not webtests"
```

:::


# Pytest More Skips

<br>

```{.python code-line-numbers="1||5|8"}
import pytest

def test_function():
    if not valid_config():
        pytest.skip("unsupported configuration")

def test_thing_with_optional_library():
    np = pytest.importorskip("numpy")
    ...
```


# Pytest: Derrick's Test Organization 

:::{.incremental}
- Organize like tests into classes
- Use fixtures when:
  - Arrange is more than ~3 lines
  - Other tests need the same setup
  - Cleanup is needed
- Fixtures should be as close to tests as possible
- Move fixtures from classes, to modules, to conftest.py
- Each python file (x.py) should have a test file (test_x.py)
- Test files mirror package org. in tests/ directory
:::


# Pytest: Derrick's Test Organization {auto-animate=true}

```python
import numpy as np

class TestThing1:
    def test_1_thing_1(self, array):
        ar = np.array([1, 2, 3])
        ...
    
    def test_2_thing_1(self, array):
        ar = np.array([1, 2, 3])
        ...
```



# Pytest: Derrick's Test Organization {auto-animate=true}

```python
import numpy as np
import pytest

class TestThing1:
    @pytest.fixture()
    def array(self):
        return np.array([1, 2, 3])
    
    def test_1_thing_1(self, array):
        ...
    
    def test_2_thing_1(self, array):
        ...
```



# Pytest: Derrick's Test Organization {auto-animate=true}

```python
import numpy as np
import pytest

@pytest.fixture()
def array():
    return np.array([1, 2, 3])

class TestThing1:
    
    def test_1_thing_1(self, array):
        ...
    
    def test_2_thing_1(self, array):
        ...

class TestThing2:
    def test_1_thing_2(self, array):
        ...
```


# Pytest: Tips/Tricks

<br>

:::{.incremental}

- --pdb flag stops after a test failure and drops into debugger
- Check coverage with [pytest-cov](https://pypi.org/project/pytest-cov/)
- Testing reqs are different for packages/libraries vs research scripts
- Pytest integrates with many IDEs (vscode, pycharm)
- Testing helps you write smaller, more modular, code
- Have fun!

:::


# Pytest DemoTime!
